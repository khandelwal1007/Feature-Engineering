{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b26cf-488f-4abb-b907-2984284dd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. What is a parameter?\n",
    "\n",
    "#ANS\n",
    "\n",
    "A parameter is a term used in various contexts, often referring to an input or variable that influences a system,\n",
    "function, or model. Its meaning depends on the field in which it is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66d0fd-aacc-42f7-a270-37fd6d892bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what is correlation?\n",
    "\n",
    "#ANS\n",
    "\n",
    "\n",
    "Correlation is a statistical concept that measures the degree to which two variables are related or move together.It quantifies the strength and direction of their relationship. Correlation does not imply causation, meaning that even if two variables are correlated,\n",
    "one does not necessarily cause the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba738b-c130-4794-9dfd-a4a9dbeb7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "\n",
    "#ANS\n",
    "\n",
    "Machine Learning (ML) is a branch of artificial intelligence (AI) that focuses on developing systems capable of learning and improving from experience without being explicitly programmed. Instead of following hard-coded instructions,\n",
    "ML models identify patterns in data to make predictions, decisions, or generate insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d1c52-a6b8-4462-a223-80d948d7198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.How does loss value help in determining whether the model is good or not?\n",
    "\n",
    "#ANS\n",
    "\n",
    "The loss value is a critical metric in machine learning that helps assess how well a model is performing.\n",
    "It measures the difference between the model's predictions and the actual target values in the training data.\n",
    "A smaller loss value typically indicates that the model's predictions are closer to the true values,\n",
    "while a larger loss value suggests poor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945fbe4-5381-4917-9530-97c666ca3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.What are continuous and categorical variables?\n",
    "\n",
    "\n",
    "#ANS\n",
    "Continuous and categorical variables are two primary types of data used in statistics and machine learning,\n",
    "differentiated by the nature of the values they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08aa96d-3e4b-49bc-97ab-afcad7ed5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "\n",
    "\n",
    "#ANS\n",
    "\n",
    "Handling categorical variables in machine learning involves transforming them into a format that\n",
    "can be understood by machine learning algorithms, \n",
    "as most models work with numerical inputs. Below are the common techniques used to preprocess and encode categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd9244-16f2-4e0b-a391-56ebbb060f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What do you mean by training and testing a dataset?\n",
    "\n",
    "\n",
    "#ANS\n",
    "Training and testing a dataset refers to the process of dividing data into subsets to develop and evaluate a machine learning model.\n",
    "This division ensures that the model is trained on one part of the data (training set) and tested on unseen data (testing set) to assess its ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef56296-d2b2-451a-9cc7-81662d98488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.What is sklearn.preprocessing?\n",
    "\n",
    "#ANS\n",
    "\n",
    "sklearn.preprocessing is a module in Scikit-learn that provides tools and utilities for preparing and transforming data before it is used in a machine learning model. Proper preprocessing ensures that data is in the right format and scaled appropriately for algorithms to work effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ddab9-9507-47a8-b950-5b4c7780860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. What is a Test set?\n",
    "\n",
    "#ANS\n",
    "A test set is a subset of the data that is used to evaluate the performance of a trained machine learning model. It contains data that the model has not seen during training, making it essential for assessing how well the model generalizes to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad38d5e-40c4-4393-becb-789db941fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "#ANS\n",
    "\n",
    "In Python, data splitting for training and testing is typically done using the train_test_split function from Scikit-learn. This function makes it simple to divide your dataset into training and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26ef3e-f40f-4324-b04a-4ef9d8f5d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.Why do we have to perform EDA before fitting a model to the data?\n",
    "\n",
    "\n",
    "#ANS\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a crucial step before fitting a model to data in machine learning. EDA helps you to better understand the dataset, detect potential issues, and make informed decisions during model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c395ed9-1c86-4e8c-b4ec-d7e0de8f72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. what is correlation.?\n",
    "\n",
    "\n",
    "\n",
    "#ANS\n",
    "\n",
    "Correlation is a statistical measure that describes the strength and direction of the relationship between two or more variables. It tells us whether and how strongly pairs of variables are related. Correlation values range from -1 to 1, with 0 indicating no relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf5a75-80cf-45b0-9fd7-83b7b6b6ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.What does negative correlation mean?\n",
    "\n",
    "#ANS\n",
    "A negative correlation means that as one variable increases, the other variable tends to decrease, and vice versa. Essentially, the two variables move in opposite directions. This type of relationship is characterized by a correlation coefficient (r) that is less than 0 but greater than -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33227155-15e9-4049-97ab-7c9ce1520230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.How can you find correlation between variables in Python?\n",
    "\n",
    "#ANS\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'X': [1, 2, 3, 4, 5],\n",
    "    'Y': [5, 4, 3, 2, 1],\n",
    "    'Z': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Pearson correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757148c-75b8-4ba8-a8ea-058e8e61b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.What is causation? Explain difference between correlation and causation with an example.?\n",
    "\n",
    "#ANS\n",
    "Causation refers to a relationship between two variables where one variable (the cause) directly influences or produces a change in another variable (the effect). In other words, causation means that a change in one variable leads to a change in another variable.\n",
    "\n",
    "\n",
    "\n",
    "Correlation: Indicates that two variables are related, but does not imply one causes the other.\n",
    "\n",
    "Causation: Implies that one variable directly causes a change in the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5905b-7f3b-47b3-b56b-6081ae2670e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2dd1c-bff5-426d-8263-9bb980346945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17.What is sklearn.linear_model ?\n",
    "\n",
    "#ANS\n",
    "sklearn.linear_model is a module in the scikit-learn library that contains algorithms for linear modeling. These models are used for both regression and classification tasks in machine learning. They model the relationship between one or more input features and an output variable, typically by fitting a linear equation to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6d6de-cbce-43cf-a1a0-8727dc45a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. What does model.fit() do? What arguments must be given.?\n",
    "\n",
    "#ANS\n",
    "In scikit-learn, the fit() method is used to train a machine learning model on a given dataset. When you call model.fit(X, y), it means you are instructing the model to learn the relationships between the input features (X) and the target labels (y). The model then fits itself to the data, adjusting its internal parameters (such as coefficients, weights, etc.) in order to minimize the loss function or optimize performance for the given problem (regression, classification, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c991e5-59be-4102-8bb9-7f4ced196f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19.What does model.predict() do? What arguments must be given?\n",
    "\n",
    "#ANS\n",
    "In scikit-learn, the model.predict() method is used to make predictions using a trained model. Once a machine learning model has been fitted to the training data using model.fit(X, y), you can use model.predict(X) to generate predictions for new, unseen data (X).\n",
    "                                                                                                                                                                                                                                             \n",
    "                                                                                                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                                                                                  \n",
    "                                                                                                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7019ba6-0365-41ef-97e9-14dcdfce42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.What are continuous and categorical variables?\n",
    "\n",
    "#ANS\n",
    "Definition: Continuous variables are numeric variables that can take any value within a given range. These values can be measured and are not restricted to discrete points. Continuous variables have an infinite number of possible values, including decimals and fractions\n",
    "\n",
    "\n",
    "Definition: Categorical variables represent types or categories. These variables contain distinct groups or classifications, which can either be nominal or ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f874c5-dfae-423a-8221-7b8de4d979dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21.What is feature scaling? How does it help in Machine Learning.?\n",
    "\n",
    "#ANS\n",
    "Feature scaling is the process of standardizing or normalizing the range of independent variables (features) in a dataset. In simpler terms, it involves transforming the features to a specific range or distribution, ensuring that each feature contributes equally to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17b397-d490-4dbb-b149-2afbc39391f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22.How do we perform scaling in Python?\n",
    "\n",
    "#ANS\n",
    "\n",
    "\n",
    "To perform feature scaling in Python, the most commonly used library is scikit-learn (sklearn), which provides built-in functions for various scaling techniques, including Normalization, Standardization, and Robust Scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e99456-07e0-43a8-b883-2c52dbd9fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23.What is sklearn.preprocessing?\n",
    "\n",
    "sklearn.preprocessing is a module from scikit-learn, a popular machine learning library in Python. This module provides functions and classes to transform and scale datasets before they are used in machine learning models. The purpose of these transformations is to make the data more suitable for a variety of machine learning algorithms, ensuring that the model performs efficiently and effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b153bc5-84de-4c07-9792-f464a62a2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24. How do we split data for model fitting (training and testing) in Python.?\n",
    "\n",
    "#ANS\n",
    "In Python, the most common way to split data into training and testing sets is by using the train_test_split() function from the scikit-learn library (sklearn.model_selection). This function randomly splits the dataset into two parts: a training set for model fitting and a testing set for evaluating model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813088d3-8b78-415c-a1b2-92600e8e28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25.Explain data encoding.?\n",
    "\n",
    "#AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9150318-a972-4b70-a2ba-dfc65a4e1942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
